# ManyLabsPSA001Analyses

Code-only repo for the Stroop ML3 + PSA001 (Social Faces) location–scale analyses.
Raw data, processed data, model draws, and reports are intentionally *not* tracked in git.

## Purpose
This project examines how trial-level variability and sampling across random facets (participants, stimuli, and sites) shape the interpretation of psychological effects. Using hierarchical location-scale models fit at the trial level, we estimate mean effects and within-person volatility jointly while allowing effects to vary across people and, where relevant, across labs and stimuli. The objective is diagnostic rather than corrective: to determine whether apparent instability reflects mean shifts, variance shifts, or differences in precision across facets, and to evaluate models using held-out trial prediction against a homoskedastic baseline.

## What is (and is not) in this repo
**Tracked (in git):**
- Analysis code (`R/`, `stan/`, `run_all.R`, `run_update_missing.R`).
- A lightweight results *snapshot* under `results/` (so reviewers can see the intended outputs without downloading large files).

**Not tracked (you generate locally):**
- `data/` (raw OSF downloads + processed CSVs).
- `models/` (CmdStan CSVs and/or saved fit objects).
- `reports/` (derived tables/plots built from fits/CV outputs).

This is intentional: the full trial datasets + model draws are large.

## Scope and decisions
- Many Smiles is excluded from the main RQs (too few repeated measures per person).
- Holdout evaluation for Stroop uses a **site-balanced subsample** for speed.
- Site K-fold comparisons are **supplemental** to RQ3 (generalization to unseen sites), not a core RQ.

## Research questions
- **RQ1 (Task comparison)**: How do within-person volatility and person-level effect heterogeneity differ between Stroop and PSA001 under the same hierarchical location-scale framework?
- **RQ2 (Direction / prevalence)**: For each task, what is the prevalence of positive, near-zero, and negative person-level effects once trial noise and person-specific variance are modeled?
- **RQ3 (Held-out prediction)**: Does modeling person-specific residual variance improve out-of-sample predictive performance (and calibration) relative to a homoskedastic mixed-effects baseline, particularly in the more variable task?

## Quick verification (recommended for reviewers)
If you want to **verify** the numbers in the tracked snapshot (`results/`) from scratch:

1) Install packages + CmdStan (first time only):
```bash
Rscript R/01_setup.R
```

2) Download raw data (see **Data download** below).

3) Build processed datasets:
```bash
Rscript R/03_make_stroop_trials_with_site.R
Rscript R/13_make_psa001_trait_dataset.R --trait attractive
Rscript R/13_make_psa001_trait_dataset.R --trait dominant
```

4) (Optional, recommended) Build the Stroop subsample for *site K-fold* (supplemental):
```bash
Rscript R/05_make_stroop_subsample.R \
  --in data/processed/trials_stroop_ml3_with_site.csv \
  --out data/processed/trials_stroop_ml3_with_site_sub30.csv \
  --per_site 30 --seed 2027
```

5) Generate missing fits/CV outputs + derived reports (this can take time):
```bash
Rscript run_update_missing.R --allow_refit true --allow_kfold true
```

6) Rebuild the summary tables/figures (fast; uses existing `reports/` inputs):
```bash
Rscript run_all.R
```

7) Compare your regenerated outputs to the tracked snapshot:
```bash
diff -ru reports results/rq_results_2026-01-02 || true
```

## Data download (not included in repo)
### Stroop (Many Labs 3) — OSF
Download and place under `data/raw/ml3/`:
- `https://osf.io/n8xa7/download` → `data/raw/ml3/StroopCleanSet.csv`
- `https://osf.io/bxw8j/download` → `data/raw/ml3/ML3AllSitesandmTurk.csv`

### PSA001 (PSA Social Faces) — OSF
Use the PSA001 project page and download the **Full data** files:
- OSF project: `https://osf.io/f7v3n/`
- Files needed: `psa001_ind.csv` and `psa001_cfd_faces.csv`

Place them at:
- `data/psa001_ind.csv`
- `data/psa001_cfd_faces.csv`

If you only have the smaller exploratory subset, run:
```bash
Rscript R/13_make_psa001_trait_dataset.R --trait dominant --ind path/to/subset_ind.csv --faces path/to/subset_faces.csv
```

## Outputs (what to look at)
### Core “paper tables” (generated locally under `reports/`)
- RQ1 (homo vs hetero parameter shift): `reports/rq1_shift_table.csv`
- RQ2 (prevalence categories): `reports/person_prevalence_summary.csv` and `reports/person_prevalence_detail.csv`
- RQ3 (trial holdout): `reports/holdout_*_summary.csv` and `reports/holdout_homo_*_summary.csv`

### Supplemental (site-generalization)
- Site variance decomposition: `reports/site_variance_decomposition.csv` and `reports/site_level_mix_precision.csv`
- Site K-fold comparison stack: `reports/site_kfold_comparison_stack.csv` (built from `reports/site_model_comparisons.csv`)

### Critique-resolution / sanity checks
- `results_checks.md` and `results_draft.md` are regenerated by `R/99_critique_resolution.R` (also run by `run_all.R`).

## Repository tour (how to navigate the R scripts)
### Top-level entrypoints (run these from repo root)
- `run_update_missing.R`: “do the work” runner; rebuilds missing intermediate outputs, and optionally refits models / runs K-fold if you pass `--allow_refit true --allow_kfold true`.
- `run_all.R`: fast “rebuild summaries” runner; assumes fits/CV outputs exist and recreates the core tables/figures and the critique-resolution docs.

### `R/` scripts by role
**Setup**
- `R/01_setup.R`: installs R packages and CmdStan.

**Data preparation**
- `R/03_make_stroop_trials_with_site.R`: builds Stroop trial CSV with `y`, `person`, `X_congruent`, `site`.
- `R/13_make_psa001_trait_dataset.R`: builds PSA001 trial CSV for a trait (e.g., `dominant`, `attractive`) with `y`, `person`, `X_male`, `site`.
- `R/05_make_stroop_subsample.R`: site-balanced participant subsample for faster CV/diagnostics.

**Model fitting (Stan)**
- `R/04_fit_stroop_location_scale.R`: fits the hierarchical location–scale model (and optionally the homoskedastic baseline) to any processed CSV.
  - Stan programs live in `stan/`.

**Held-out trials (within-person)**
- `R/18_holdout_pipeline.R`: end-to-end helper (make holdout → fit → evaluate) for PSA001 (and optionally Stroop).
- `R/17_trial_holdout_predict.R`: creates holdout indicators and evaluates predictions from participant posterior means.
- `R/19_holdout_eval_homo.R`: evaluates holdout predictions for the homoskedastic baseline using summary means.

**Site generalization (supplemental)**
- `R/11_kfold_location_scale.R`: site/person K-fold CV for hetero vs homo (robust alternative to grouped PSIS-LOO).
- `R/06_site_models_table.R`: compiles per-dataset hetero-vs-homo comparisons into a single table.
- `R/09_site_kfold_stack.R`: stacks site K-fold comparison outputs + variance decomposition into one view.
- `R/08_site_variance_decomp.R`: site-level mix/precision decomposition using participant summaries.

**Results + checks**
- `R/07_participants_prevalence.R`: prevalence categories from participant tables (responders / opposite / ROPE / uncertain).
- `R/12_rq1_shift_table.R`: extracts `beta[2]` and `tau_site[2]` from hetero vs homo summaries.
- `R/99_critique_resolution.R`: builds `results_checks.md`, `results_draft.md`, and outlier/diagnostic plots.

**Optional PSA001 “why do people diverge?” analyses (exploratory)**
- `R/exploratory/14_psa001_divergence_models.R`, `R/exploratory/15_psa001_cluster_analysis.R`, `R/exploratory/16_psa001_covariate_sweep.R`: exploratory/supporting analyses of subgroup structure and covariates.

### `R/lib/` (shared utilities)
These are sourced by multiple scripts to reduce duplication:
- `R/lib/cli_utils.R`: consistent `--flag` parsing helpers.
- `R/lib/file_utils.R`: path helpers + fallback to archived report files by basename.
- `R/lib/prevalence_utils.R`: person↔site mapping + direction detection utilities.

### `R/utils/` (optional helpers)
Not required for reproducing RQ1–RQ3, but useful during development/QA:
- `R/utils/00_counts_table.R`: quick per-site counts sanity checks.
- `R/utils/00_backfill_manifest_from_cmdstan.R`: reconstruct `reports/run_manifest.csv` from older CmdStan CSV headers.

## Results snapshot (tracked)
A lightweight snapshot of the *intended outputs* is tracked under `results/` so others can audit what the pipeline produces.
- Latest: `results/rq_results_2026-01-02/`
- Older snapshots are kept for reference.

## Notes on compute and reproducibility
- Model fitting and K-fold CV can be slow (minutes → hours) depending on hardware.
- Most scripts use fixed seeds (e.g., `2027`) for deterministic subsampling/holdouts where applicable.
- If CmdStan is installed in a non-default location, set `CMDSTAN` or `CMDSTAN_OVERRIDE` before running fits.
